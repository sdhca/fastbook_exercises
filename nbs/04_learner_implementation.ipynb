{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a57815-2ea2-44a1-a76d-94d0cd365635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# ! [ -e /content ] && pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cbd068-6790-456a-8bfb-808c1ead7c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4799a19-7073-479c-a1d9-44e6c52aae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae898e4e-3cf2-4a8d-a85a-633a775bcaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffb97db-3208-419f-90ad-452cbeff43a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aba5c91-31d9-4ecf-8479-3b1f30127a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6131) [Path('train/3/10.png'),Path('train/3/10000.png'),Path('train/3/10011.png'),Path('train/3/10031.png'),Path('train/3/10034.png'),Path('train/3/10042.png'),Path('train/3/10052.png'),Path('train/3/1007.png'),Path('train/3/10074.png'),Path('train/3/10091.png')...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "threes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7f618f-ae8e-4eb8-9193-f97ce0b79ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6131, 6265)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "len(three_tensors),len(seven_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b9195d-7791-4b71-a0b0-f1bd248b4403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6131, 28, 28])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "stacked_threes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f1e835-f63f-417a-a78a-f58e50264806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12396, 784]), torch.Size([12396, 1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n",
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n",
    "train_x.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee3d7aa-2133-48b1-b081-f819271d9868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = list(zip(train_x,train_y))\n",
    "x,y = dset[0]\n",
    "x.shape,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1137c752-4d71-4e50-b7e0-3b83ed248838",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cef4fe6-6137-4a19-a4f2-ae929d423874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_3_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'3').ls()])\n",
    "valid_3_tens = valid_3_tens.float()/255\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'7').ls()])\n",
    "valid_7_tens = valid_7_tens.float()/255\n",
    "valid_3_tens.shape,valid_7_tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234184f9-0a60-4fb4-a826-519ccc8a84ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\n",
    "valid_dset = list(zip(valid_x,valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d3a409-28c0-417c-85eb-a2497fed9bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_dset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b36bc03-1b1e-4419-9d1b-d9d08fec6f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.data.core.DataLoaders>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = DataLoaders(dl, valid_dl)\n",
    "dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5549cbba-698d-4af5-9bdd-534683eeddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a503ddc-b81b-4569-9595-1488edeb82fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()\n",
    "\n",
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4dfde-57bc-4b29-b2b8-4fbc21e37773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67993197-edd8-4f15-b483-648c6b838248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import IPython.display as dsp\n",
    "# from IPython.display import HTML, display\n",
    "\n",
    "class MyLearner:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 dls,\n",
    "                 model: 'callable',\n",
    "                 opt_func: 'callable',\n",
    "                 metrics: 'callable',\n",
    "                 loss_func: 'callable | None' = None,\n",
    "                 lr: float = 0.001):\n",
    "        self.dls = dls\n",
    "        self.model = model\n",
    "        # self.model = model.cuda()\n",
    "        self.metrics = metrics\n",
    "        self.loss_func = loss_func\n",
    "        self.opt_func = opt_func\n",
    "        self.lr = lr\n",
    "        self.training_summary = pd.DataFrame(columns=['epoch', 'train_loss', 'valid_loss', 'metric', 'time'])\n",
    "    \n",
    "    def _validate_epoch(self, model, valid_dl):\n",
    "        # batch_losses = [self.loss_func(model(xb), yb) for xb, yb in valid_dl]\n",
    "        # batch_metrics = [self.metrics(model(xb), yb) for xb,yb in valid_dl]\n",
    "\n",
    "        batch_losses = []\n",
    "        batch_metrics = []\n",
    "        for xb, yb in valid_dl:\n",
    "            # xb = xb.cuda()\n",
    "            # yb = yb.cuda()\n",
    "            yhat = model(xb)\n",
    "            batch_losses.append(self.loss_func(yhat, yb))\n",
    "            batch_metrics.append(self.metrics(yhat, yb))                             \n",
    "\n",
    "        return torch.stack(batch_losses).mean().item(), torch.stack(batch_metrics).mean().item()\n",
    "    \n",
    "    def debug(self):\n",
    "        print(self.model.parameters())\n",
    "    \n",
    "    def fit(self, n_epoch: int = 10, lr: 'float | None' = None):\n",
    "        if not lr:\n",
    "            lr = self.lr\n",
    "        \n",
    "        # Initialize training progress display\n",
    "        self.training_summary = self.training_summary[0:0]\n",
    "        progress_bar = widgets.IntProgress(value=0, min=1, max=n_epoch+1, step=1, description=f'epoch [0 / {n_epoch}]')\n",
    "        dsp.display(progress_bar, dsp.HTML(self.training_summary.to_html(index=False)))\n",
    "        \n",
    "        # Initialize optimizer\n",
    "        params = self.model.parameters()\n",
    "        optimizer = self.opt_func(params, lr=lr)\n",
    "            \n",
    "        # Training loop\n",
    "        for i in range(n_epoch):\n",
    "            # Train\n",
    "            t0 = time.time()\n",
    "\n",
    "            epoch_train_loss = 0.0\n",
    "            num_batches = 0\n",
    "            for xb, yb in self.dls.train_ds:\n",
    "                # xb = xb.cuda()\n",
    "                # yb = yb.cuda()\n",
    "                num_batches += 1\n",
    "                preds = self.model(xb)\n",
    "                loss = self.loss_func(preds, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                epoch_train_loss += loss.item()\n",
    "            epoch_train_loss /= num_batches\n",
    "            \n",
    "            # Validation\n",
    "            epoch_valid_loss, epoch_valid_metric = self._validate_epoch(self.model, self.dls.valid_ds)\n",
    "            \n",
    "            # Update training progress display\n",
    "            progress_bar.value += 1\n",
    "            progress_bar.description = f'epoch [{i+1} / {n_epoch}]'\n",
    "            t1 = time.time()\n",
    "            epoch_summary = pd.DataFrame([{'epoch': i, 'train_loss': epoch_train_loss, 'valid_loss': epoch_valid_loss, 'metric': epoch_valid_metric, 'time': t1-t0}])\n",
    "            self.training_summary = pd.concat([self.training_summary, epoch_summary])\n",
    "            dsp.clear_output()\n",
    "            dsp.display(progress_bar, dsp.HTML(self.training_summary.to_html(index=False)))\n",
    "            \n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f82146-e1f7-4065-bca2-d9984d67195e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9280f76e2544682918cbab5a8a0e579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=101, description='epoch [100 / 100]', max=101, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>metric</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.049406</td>\n",
       "      <td>0.495250</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>4.775875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.013176</td>\n",
       "      <td>0.467802</td>\n",
       "      <td>0.518646</td>\n",
       "      <td>4.803080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.002175</td>\n",
       "      <td>0.309720</td>\n",
       "      <td>0.691364</td>\n",
       "      <td>4.753184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>0.232236</td>\n",
       "      <td>0.770363</td>\n",
       "      <td>4.737833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>0.205233</td>\n",
       "      <td>0.797841</td>\n",
       "      <td>4.756465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.169007</td>\n",
       "      <td>0.831698</td>\n",
       "      <td>4.731095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.173928</td>\n",
       "      <td>0.823847</td>\n",
       "      <td>4.770639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.168797</td>\n",
       "      <td>0.831207</td>\n",
       "      <td>4.794704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.165645</td>\n",
       "      <td>0.836114</td>\n",
       "      <td>4.785752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.116815</td>\n",
       "      <td>0.881747</td>\n",
       "      <td>4.859257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.119699</td>\n",
       "      <td>0.882728</td>\n",
       "      <td>4.805227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.116852</td>\n",
       "      <td>0.882728</td>\n",
       "      <td>4.772180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.149107</td>\n",
       "      <td>0.849853</td>\n",
       "      <td>4.842525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.135520</td>\n",
       "      <td>0.864573</td>\n",
       "      <td>4.746285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.147145</td>\n",
       "      <td>0.854269</td>\n",
       "      <td>4.761688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.147930</td>\n",
       "      <td>0.850343</td>\n",
       "      <td>4.772647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.095594</td>\n",
       "      <td>0.904809</td>\n",
       "      <td>4.816638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.089168</td>\n",
       "      <td>0.911187</td>\n",
       "      <td>4.773445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.083931</td>\n",
       "      <td>0.918057</td>\n",
       "      <td>4.787578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.120379</td>\n",
       "      <td>0.879784</td>\n",
       "      <td>4.769793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.095569</td>\n",
       "      <td>0.905790</td>\n",
       "      <td>4.777645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.073414</td>\n",
       "      <td>0.926398</td>\n",
       "      <td>4.876940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.087296</td>\n",
       "      <td>0.912659</td>\n",
       "      <td>4.712393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.060638</td>\n",
       "      <td>0.938175</td>\n",
       "      <td>4.785285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.098682</td>\n",
       "      <td>0.899902</td>\n",
       "      <td>4.776708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.070290</td>\n",
       "      <td>0.928361</td>\n",
       "      <td>4.811462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>0.056263</td>\n",
       "      <td>0.944063</td>\n",
       "      <td>4.752405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.061736</td>\n",
       "      <td>0.938175</td>\n",
       "      <td>4.781645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.062675</td>\n",
       "      <td>0.937684</td>\n",
       "      <td>4.764535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.059167</td>\n",
       "      <td>0.940628</td>\n",
       "      <td>4.811470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.062336</td>\n",
       "      <td>0.937684</td>\n",
       "      <td>4.788228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.001602</td>\n",
       "      <td>0.045351</td>\n",
       "      <td>0.954858</td>\n",
       "      <td>4.716091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.046083</td>\n",
       "      <td>0.954367</td>\n",
       "      <td>4.872448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>0.047935</td>\n",
       "      <td>0.953386</td>\n",
       "      <td>4.805543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>0.039505</td>\n",
       "      <td>0.960746</td>\n",
       "      <td>4.759612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.027865</td>\n",
       "      <td>0.970559</td>\n",
       "      <td>4.730340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.036005</td>\n",
       "      <td>0.964181</td>\n",
       "      <td>4.751736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.035179</td>\n",
       "      <td>0.965162</td>\n",
       "      <td>4.817628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.032602</td>\n",
       "      <td>0.967615</td>\n",
       "      <td>4.798330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.023290</td>\n",
       "      <td>0.977429</td>\n",
       "      <td>4.757409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.032838</td>\n",
       "      <td>0.968106</td>\n",
       "      <td>4.854859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.026412</td>\n",
       "      <td>0.973013</td>\n",
       "      <td>4.839490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.022917</td>\n",
       "      <td>0.977429</td>\n",
       "      <td>4.821573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.020512</td>\n",
       "      <td>0.979392</td>\n",
       "      <td>4.807361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>0.031622</td>\n",
       "      <td>0.968106</td>\n",
       "      <td>4.854872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.025052</td>\n",
       "      <td>0.975466</td>\n",
       "      <td>4.816450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.021175</td>\n",
       "      <td>0.978901</td>\n",
       "      <td>4.769080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.027296</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>4.856658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.028471</td>\n",
       "      <td>0.971050</td>\n",
       "      <td>4.974195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.016525</td>\n",
       "      <td>0.983317</td>\n",
       "      <td>4.767992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.013903</td>\n",
       "      <td>0.986261</td>\n",
       "      <td>5.257133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.020029</td>\n",
       "      <td>0.980373</td>\n",
       "      <td>4.828779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.013628</td>\n",
       "      <td>0.986261</td>\n",
       "      <td>4.778996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.017950</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>4.784702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.013442</td>\n",
       "      <td>0.986752</td>\n",
       "      <td>4.850488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.014109</td>\n",
       "      <td>0.986261</td>\n",
       "      <td>4.820334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.014592</td>\n",
       "      <td>0.985280</td>\n",
       "      <td>4.921556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.012810</td>\n",
       "      <td>0.987242</td>\n",
       "      <td>4.809571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.012902</td>\n",
       "      <td>0.987242</td>\n",
       "      <td>4.824624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.012060</td>\n",
       "      <td>0.987242</td>\n",
       "      <td>4.841805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.013521</td>\n",
       "      <td>0.987242</td>\n",
       "      <td>4.852477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.009170</td>\n",
       "      <td>0.990677</td>\n",
       "      <td>4.799706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.988714</td>\n",
       "      <td>4.827698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.009318</td>\n",
       "      <td>0.990186</td>\n",
       "      <td>4.744569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.009269</td>\n",
       "      <td>0.990677</td>\n",
       "      <td>4.791419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.009175</td>\n",
       "      <td>0.991168</td>\n",
       "      <td>4.743106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.010151</td>\n",
       "      <td>0.989696</td>\n",
       "      <td>4.789361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.008801</td>\n",
       "      <td>0.991168</td>\n",
       "      <td>4.771404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.008310</td>\n",
       "      <td>0.991659</td>\n",
       "      <td>4.772909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.009085</td>\n",
       "      <td>0.990677</td>\n",
       "      <td>4.807647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.008675</td>\n",
       "      <td>0.990677</td>\n",
       "      <td>4.839441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.008241</td>\n",
       "      <td>0.992149</td>\n",
       "      <td>4.841657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.008186</td>\n",
       "      <td>0.991659</td>\n",
       "      <td>4.804679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.008576</td>\n",
       "      <td>0.991168</td>\n",
       "      <td>4.771681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.990677</td>\n",
       "      <td>4.787976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.008775</td>\n",
       "      <td>0.991168</td>\n",
       "      <td>4.790311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.992149</td>\n",
       "      <td>4.898542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.009239</td>\n",
       "      <td>0.990677</td>\n",
       "      <td>4.797886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.009107</td>\n",
       "      <td>0.990677</td>\n",
       "      <td>5.053151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.008321</td>\n",
       "      <td>0.991659</td>\n",
       "      <td>4.999204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.007521</td>\n",
       "      <td>0.992640</td>\n",
       "      <td>5.011430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.008410</td>\n",
       "      <td>0.991659</td>\n",
       "      <td>4.940299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.008048</td>\n",
       "      <td>0.991659</td>\n",
       "      <td>5.049952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.008644</td>\n",
       "      <td>0.991659</td>\n",
       "      <td>5.018923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.008063</td>\n",
       "      <td>0.992149</td>\n",
       "      <td>4.849853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>0.993131</td>\n",
       "      <td>4.898929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>0.992149</td>\n",
       "      <td>5.082910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.008275</td>\n",
       "      <td>0.991659</td>\n",
       "      <td>5.100795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.992149</td>\n",
       "      <td>4.862840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.008195</td>\n",
       "      <td>0.991659</td>\n",
       "      <td>4.804569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.008348</td>\n",
       "      <td>0.991659</td>\n",
       "      <td>4.826790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.009125</td>\n",
       "      <td>0.990677</td>\n",
       "      <td>4.846092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.008432</td>\n",
       "      <td>0.991659</td>\n",
       "      <td>4.901841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.007534</td>\n",
       "      <td>0.992640</td>\n",
       "      <td>4.956468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.007496</td>\n",
       "      <td>0.992640</td>\n",
       "      <td>5.007829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.007475</td>\n",
       "      <td>0.992640</td>\n",
       "      <td>4.944803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.007455</td>\n",
       "      <td>0.992640</td>\n",
       "      <td>4.901295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.007441</td>\n",
       "      <td>0.992640</td>\n",
       "      <td>4.823715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.007427</td>\n",
       "      <td>0.992640</td>\n",
       "      <td>4.897778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.007415</td>\n",
       "      <td>0.992640</td>\n",
       "      <td>4.834429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1)\n",
    ")\n",
    "\n",
    "learner = MyLearner(dls, simple_net, opt_func=SGD, loss_func=mnist_loss, metrics=batch_accuracy)\n",
    "\n",
    "# learner.debug()\n",
    "learner.fit(100, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d41f373-5dcc-4fd3-89ca-6d1f68fb4d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = widgets.Output()\n",
    "with out:\n",
    "    for i in range(10):\n",
    "        print(i, 'Hello world!')\n",
    "    # out\n",
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccdeb69-12f1-42fb-b340-b866295eacc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'callable'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mloss_func\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'callable | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mopt_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mfunction\u001b[0m \u001b[0mAdam\u001b[0m \u001b[0mat\u001b[0m \u001b[0;36m0x7f1fefe194c0\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msplitter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'callable'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mfunction\u001b[0m \u001b[0mtrainable_params\u001b[0m \u001b[0mat\u001b[0m \u001b[0;36m0x7f1ff3764c10\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwd_bn_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrain_bn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.85\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdefault_cbs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      Group together a `model`, some `dls` and a `loss_func` to handle training\n",
       "\u001b[0;31mFile:\u001b[0m           ~/mambaforge/envs/fastai/lib/python3.9/site-packages/fastai/learner.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1332296f-f14b-43dd-be0a-d606b48cd55c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
